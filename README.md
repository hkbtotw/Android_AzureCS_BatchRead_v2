# Android_AzureCS_BatchRead_v2
Integrated Camera upload, Cropping and Image processing to v1

<p><i> Android Application connected with Azure Cognitive Service - Batch Read API   </i> </p>
<p><i> In version 2, Camera upload, Image processing and Cropping functionalities were added </i> </p>

<p>Next</p>
<p>To add parseServer functionality to allow program to compute total miles covered in trip and the save in the server </p>


<b> Sample Images:<br/></b>
<p>Android Application</p>

Main page
<img src=https://github.com/hkbtotw/Android_AzureCS_BatchRead_v2/blob/master/screenCapture/Screen01.jpg alt="Demo UI" width="200"/>

Taking photo of the odometer and cropping the digitbar for processing
<img src=https://github.com/hkbtotw/Android_AzureCS_BatchRead_v2/blob/master/screenCapture/Screen02.jpg alt="Demo UI" width="200"/>

Recognized miles by Azure Cognitive Service or Google Textrecognition presented for review on screen ; users can check the result and edit if needed.
<img src=https://github.com/hkbtotw/Android_AzureCS_BatchRead_v2/blob/master/screenCapture/Screen03.jpg alt="Demo UI" width="200"/>

Recording the recognized miles to parse server
<img src=https://github.com/hkbtotw/Android_AzureCS_BatchRead_v2/blob/master/screenCapture/Screen04.jpg alt="Demo UI" width="200"/>

Recording the traveling distance by using device's latitude and longitude; the traveling distance computed from this method shown on screen together with the traveling duration since the beginning of the trip. Furthermore, once the trip ends, the total traveling distance computed from device's latitude and longtiude is computed and logged in the parser server for analysis.
<img src=https://github.com/hkbtotw/Android_AzureCS_BatchRead_v2/blob/master/screenCapture/Screen06.jpg alt="Demo UI" width="200"/>

Once the trip is over, the trip summary can be viewed by user.
<img src=https://github.com/hkbtotw/Android_AzureCS_BatchRead_v2/blob/master/screenCapture/Screen07.jpg alt="Demo UI" width="200"/>
